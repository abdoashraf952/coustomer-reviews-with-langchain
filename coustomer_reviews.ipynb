{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691c3068",
   "metadata": {},
   "source": [
    "# 1) Install & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2659df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xmanager 0.7.1 requires sqlalchemy==1.2.19, but you have sqlalchemy 2.0.45 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 19:13:33.201849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768850013.393017      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768850013.448649      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768850013.916626      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768850013.916670      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768850013.916673      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768850013.916676      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install -q transformers==4.53.3 langchain gspread google-auth pandas fastapi uvicorn pyngrok accelerate\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from collections import Counter\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "import re\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI, Request, HTTPException\n",
    "import uvicorn, threading, time, socket\n",
    "from pyngrok import ngrok, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc512a4",
   "metadata": {},
   "source": [
    "# 2) Sentiment Analysis Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36241447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99eda80bc5a456cbe02d0c9df4dc886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3f432ba9ea457cae1f4ca27493d847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5586ddd88fe747259ae4b3ed37e3eecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cf9131765e4e1e8b955bbea3218792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22a6be",
   "metadata": {},
   "source": [
    "# 3) Load LLM (Mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a910b411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f7649bd34845599e92d78a03043f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ad27e2250c41e4802b6e42fc9f8767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a058a38e613491baca985a24d6ad591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016615f39de14af38bbf7d3f22b10999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d837e7937f6c40598369f1d7a7a2a4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f6cb7b09134c37bff763ba40171d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a81e94d541841cca892d23104d4df6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab8276e910d4050a808ef73714399d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e271a4fbfa1447ddbf8e6d64d306aa5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54a28145a064283b71f1f39698093a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceaf3c7fdaa946e9a83f1c98f9d655ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4209fd2c229c4b32b5fd8435e4f5a749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259e35a8d56941ca8a193d00fe3663e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173bb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=15000, num_return_sequences=1):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a6d13",
   "metadata": {},
   "source": [
    "# 4) Custom LangChain LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a444f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomHFLLM(LLM):\n",
    "    def _call(self, prompt: str, stop=None) -> str:\n",
    "        return generate_text(prompt)\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom_huggingface\"\n",
    "\n",
    "llm = CustomHFLLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b40e10",
   "metadata": {},
   "source": [
    "# 5) Chain → Extract Main Problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457b6fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/3945071181.py:16: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  problem_chain = LLMChain(llm=llm, prompt=problem_prompt)\n"
     ]
    }
   ],
   "source": [
    "problem_prompt = PromptTemplate(\n",
    "    input_variables=[\"review\"],\n",
    "    template=\"\"\"\n",
    "        You are an expert customer complaint analyst.\n",
    "\n",
    "        From the following NEGATIVE review, extract ONLY ONE main problem\n",
    "        as a very short clear phrase.\n",
    "\n",
    "        Return ONLY the problem text, nothing else.\n",
    "\n",
    "        Review:\n",
    "        \"{review}\"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "problem_chain = LLMChain(llm=llm, prompt=problem_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ed7a5",
   "metadata": {},
   "source": [
    "# 6) Output Parser Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac524717",
   "metadata": {},
   "outputs": [],
   "source": [
    "Problem_schema = ResponseSchema(\n",
    "    name=\"Problem\",\n",
    "    description=\"The main recurring problem.\"\n",
    ")\n",
    "\n",
    "total_occurrences_schema = ResponseSchema(\n",
    "    name=\"Number of occurrences\",\n",
    "    description=\"How many customers reported this problem.\"\n",
    ")\n",
    "\n",
    "severity_level_schema = ResponseSchema(\n",
    "    name=\"Severity level\",\n",
    "    description=\"Severity from 1 (minor) to 5 (critical).\"\n",
    ")\n",
    "\n",
    "solution_prompt = ResponseSchema(\n",
    "    name='Suggested Solution',\n",
    "    description=\"As an expert customer service manager, suggest the best way to resolve the following problem ,Provide a concise resolution plan.\"\n",
    "    )\n",
    "\n",
    "response_schemas = [\n",
    "    Problem_schema,\n",
    "    total_occurrences_schema,\n",
    "    severity_level_schema,\n",
    "    solution_prompt\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86d285",
   "metadata": {},
   "source": [
    "# 7) Chain → Severity + Structured Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1bca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt_template = \"\"\"\n",
    "    You are an expert customer experience analyst.\n",
    "\n",
    "    Based on the following recurring problem and statistics, generate a structured report.\n",
    "\n",
    "    Problem: {problem}\n",
    "    Number of occurrences: {count}\n",
    "\n",
    "    Decide the severity level from 1 to 5:\n",
    "    1 = very minor\n",
    "    3 = moderate\n",
    "    5 = critical (safety, payment, trust, delivery loss)\n",
    "\n",
    "    suggest a concise resolution plan to address this problem effectively.\n",
    "\n",
    "    Return ONLY valid JSON following this schema between '```json and ```'.\n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "final_prompt = PromptTemplate(\n",
    "    input_variables=[\"problem\", \"count\", \"format_instructions\"],\n",
    "    template=final_prompt_template\n",
    ")\n",
    "\n",
    "final_chain = LLMChain(llm=llm, prompt=final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161bcdd",
   "metadata": {},
   "source": [
    "# 8) extract the last JSON block from a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43041960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_block(text):\n",
    "    pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    return f\"```json\\n{matches[-1]}\\n```\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90ef2b",
   "metadata": {},
   "source": [
    "# 9) Google Sheet Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f0d2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "    \"https://www.googleapis.com/auth/drive\"\n",
    "]\n",
    "\n",
    "creds = Credentials.from_service_account_file(\n",
    "    \"/kaggle/input/storied-mantra-457512-f7-5c671f415114/storied-mantra-457512-f7-5c671f415114.json\",\n",
    "    scopes=SCOPES\n",
    ")\n",
    "\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "sheet = client.open_by_url(\"https://docs.google.com/spreadsheets/d/19_axzwI81tKb3vZazRHy8KQnTAZeQajal6MKhOl6zr4/edit?gid=0#gid=0\").sheet1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79642d2",
   "metadata": {},
   "source": [
    "# 10) Main System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9263db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "        \n",
    "    data = sheet.get_all_records()\n",
    "    reviews = [record['Reviews'] for record in data]\n",
    "\n",
    "\n",
    "\n",
    "    # ---- Step 1: Sentiment filtering\n",
    "    negative_reviews = []\n",
    "    for r in reviews:\n",
    "        result = sentiment_pipeline(r)[0]\n",
    "        if result[\"label\"] == \"NEGATIVE\":\n",
    "            negative_reviews.append(r)\n",
    "\n",
    "    print(\"Negative Reviews:\", len(negative_reviews))\n",
    "\n",
    "    # ---- Step 2: Extract problems\n",
    "    problems = []\n",
    "    for review in negative_reviews:\n",
    "        p = problem_chain.run(review=review).strip()\n",
    "        problems.append(p)\n",
    "\n",
    "    print(\"\\nExtracted Problems:\")\n",
    "    print(problems)\n",
    "\n",
    "    # ---- Step 3: Count recurring problems\n",
    "    counter = Counter(problems)\n",
    "    most_common_problem, count = counter.most_common(1)[0]\n",
    "\n",
    "    print(\"\\nMost Common Problem:\", most_common_problem)\n",
    "    print(\"Occurrences:\", count)\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for problem, count in counter.items():\n",
    "\n",
    "        final_response = final_chain.run(\n",
    "            problem=problem,\n",
    "            count=count,\n",
    "            format_instructions=format_instructions\n",
    "        )\n",
    "\n",
    "        json_text = extract_json_block(final_response)\n",
    "\n",
    "        output_data = output_parser.parse(json_text)\n",
    "        final_results.append(output_data)\n",
    "\n",
    "    print(\"\\n✅ Final Structured Output:\\n\")\n",
    "    for result in final_results:\n",
    "        print(result)\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "968c3df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Reviews: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Problems:\n",
      "['You are an expert customer complaint analyst.\\n\\n        From the following NEGATIVE review, extract ONLY ONE main problem\\n        as a very short clear phrase.\\n\\n        Return ONLY the problem text, nothing else.\\n\\n        Review:\\n        \"The product arrived damaged and customer service ignored me.\"\\n        Problem:', 'You are an expert customer complaint analyst.\\n\\n        From the following NEGATIVE review, extract ONLY ONE main problem\\n        as a very short clear phrase.\\n\\n        Return ONLY the problem text, nothing else.\\n\\n        Review:\\n        \"My order came broken and no one replied to my emails.\"\\n        ----> \"Order arrived broken\"', 'You are an expert customer complaint analyst.\\n\\n        From the following NEGATIVE review, extract ONLY ONE main problem\\n        as a very short clear phrase.\\n\\n        Return ONLY the problem text, nothing else.\\n\\n        Review:\\n        \"Worst experience ever, the item was damaged.\"\\n        Problem: Item damaged', 'You are an expert customer complaint analyst.\\n\\n        From the following NEGATIVE review, extract ONLY ONE main problem\\n        as a very short clear phrase.\\n\\n        Return ONLY the problem text, nothing else.\\n\\n        Review:\\n        \"Customer support never responds and my product was faulty.\"\\n        Problem:\\n        - No response from customer support\\n        \"I\\'ve been waiting for my refund for 2 months now and still no\\n        response from the company.\"\\n        Problem:\\n        - Long wait for refund\\n        \"I\\'ve had to contact customer service multiple times to get my\\n        issue resolved. It\\'s been a week and they still haven\\'t fixed my\\n        problem.\"\\n        Problem:\\n        - Slow issue resolution\\n        \"The product arrived damaged and the company refused to accept\\n        responsibility.\"\\n        Problem:\\n        - Refusal to accept responsibility']\n",
      "\n",
      "Most Common Problem: You are an expert customer complaint analyst.\n",
      "\n",
      "        From the following NEGATIVE review, extract ONLY ONE main problem\n",
      "        as a very short clear phrase.\n",
      "\n",
      "        Return ONLY the problem text, nothing else.\n",
      "\n",
      "        Review:\n",
      "        \"The product arrived damaged and customer service ignored me.\"\n",
      "        Problem:\n",
      "Occurrences: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Structured Output:\n",
      "\n",
      "{'Problem': 'Product damage', 'Number of occurrences': '1', 'Severity level': '3', 'Suggested Solution': 'Implement a more robust packaging process and provide clear instructions to customers on how to inspect the product upon delivery. Additionally, train customer service representatives to immediately address and escalate damaged product complaints.'}\n",
      "{'Problem': 'Order arrived broken', 'Number of occurrences': '1', 'Severity level': '3', 'Suggested Solution': 'Implement a rigorous quality check process before dispatching. Train staff to handle products with care and provide clear instructions on packaging. Offer immediate replacement or refund if the customer reports a broken item.'}\n",
      "{'Problem': 'Payment gateway failure', 'Number of occurrences': '2', 'Severity level': '5', 'Suggested Solution': 'Test and optimize payment gateway integration, provide alternative payment methods, and offer assistance to customers experiencing payment issues.'}\n",
      "{'Problem': 'Damaged product and slow response from customer support', 'Number of occurrences': '1', 'Severity level': '5', 'Suggested Solution': 'Implement rigorous quality checks, increase staffing, prioritize response time, automate updates'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Problem': 'Product damage',\n",
       "  'Number of occurrences': '1',\n",
       "  'Severity level': '3',\n",
       "  'Suggested Solution': 'Implement a more robust packaging process and provide clear instructions to customers on how to inspect the product upon delivery. Additionally, train customer service representatives to immediately address and escalate damaged product complaints.'},\n",
       " {'Problem': 'Order arrived broken',\n",
       "  'Number of occurrences': '1',\n",
       "  'Severity level': '3',\n",
       "  'Suggested Solution': 'Implement a rigorous quality check process before dispatching. Train staff to handle products with care and provide clear instructions on packaging. Offer immediate replacement or refund if the customer reports a broken item.'},\n",
       " {'Problem': 'Payment gateway failure',\n",
       "  'Number of occurrences': '2',\n",
       "  'Severity level': '5',\n",
       "  'Suggested Solution': 'Test and optimize payment gateway integration, provide alternative payment methods, and offer assistance to customers experiencing payment issues.'},\n",
       " {'Problem': 'Damaged product and slow response from customer support',\n",
       "  'Number of occurrences': '1',\n",
       "  'Severity level': '5',\n",
       "  'Suggested Solution': 'Implement rigorous quality checks, increase staffing, prioritize response time, automate updates'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c363d31",
   "metadata": {},
   "source": [
    "# 11) END_Point_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a827b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill the ngrok process if running\n",
    "ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05ceaaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGROK_TOKEN = \"33N5iIyI0DDMRt0vMWzjkQ7G61b_YjVQYahGWxy8Xds3ZsVw\"\n",
    "API_KEY = \"secret123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66a5c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/show_reviews\")\n",
    "async def gen(req: Request):\n",
    "    if req.headers.get(\"authorization\") != f\"Bearer {API_KEY}\":\n",
    "        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n",
    "\n",
    "    return {\n",
    "        \"response\": main()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efb9d379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your public URL: https://tamiko-unidealized-discernibly.ngrok-free.dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [55]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:58245 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Reviews: 4\n"
     ]
    }
   ],
   "source": [
    "def free_port():\n",
    "    s = socket.socket()\n",
    "    s.bind(('', 0))\n",
    "    port = s.getsockname()[1]\n",
    "    s.close()\n",
    "    return port\n",
    "\n",
    "port = free_port()\n",
    "conf.get_default().auth_token = NGROK_TOKEN\n",
    "public_url = ngrok.connect(port).public_url\n",
    "print(\"Your public URL:\", public_url)\n",
    "\n",
    "def run(): uvicorn.run(app, host=\"0.0.0.0\", port=port)\n",
    "threading.Thread(target=run, daemon=True).start()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5e60ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdoa\\anaconda3\\envs\\ml\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'tamiko-unidealized-discernibly.ngrok-free.dev'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS: 200\n",
      "RAW RESPONSE:\n",
      " {\"response\":[{\"Problem\":\"Late or missing delivery\",\"Number of occurrences\":\"1000\",\"Severity level\":\"5\",\"Suggested Solution\":\"Implement a robust tracking system, offer real-time updates to customers, and provide clear communication on expected delivery times. Additionally, establish a reliable process for resolving missing packages promptly.\"},{\"Problem\":\"Cold food, slow service\",\"Number of occurrences\":\"1\",\"Severity level\":\"3\",\"Suggested Solution\":\"Implement a new system to track food temperature and service speed in real-time. Train staff to prioritize speed and quality. Offer free drinks or appetizers to customers who experience long wait times.\"}]}\n",
      "{'response': [{'Problem': 'Late or missing delivery', 'Number of occurrences': '1000', 'Severity level': '5', 'Suggested Solution': 'Implement a robust tracking system, offer real-time updates to customers, and provide clear communication on expected delivery times. Additionally, establish a reliable process for resolving missing packages promptly.'}, {'Problem': 'Cold food, slow service', 'Number of occurrences': '1', 'Severity level': '3', 'Suggested Solution': 'Implement a new system to track food temperature and service speed in real-time. Train staff to prioritize speed and quality. Offer free drinks or appetizers to customers who experience long wait times.'}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "headers = {\"Authorization\": \"Bearer secret123\"}\n",
    "API_URL = \"https://tamiko-unidealized-discernibly.ngrok-free.dev/show_reviews\"\n",
    "   \n",
    "res = requests.post(API_URL, headers=headers, verify=False)\n",
    "print(\"STATUS:\", res.status_code)\n",
    "print(\"RAW RESPONSE:\\n\", res.text)\n",
    "\n",
    "data = res.json()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e01d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
